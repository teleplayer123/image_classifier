{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edgetpu.dll\n",
      "Help on Delegate in module tflite_runtime.interpreter object:\n",
      "\n",
      "class Delegate(builtins.object)\n",
      " |  Delegate(library, options=None)\n",
      " |  \n",
      " |  Python wrapper class to manage TfLiteDelegate objects.\n",
      " |  \n",
      " |  The shared library is expected to have two functions:\n",
      " |    TfLiteDelegate* tflite_plugin_create_delegate(\n",
      " |        char**, char**, size_t, void (*report_error)(const char *))\n",
      " |    void tflite_plugin_destroy_delegate(TfLiteDelegate*)\n",
      " |  \n",
      " |  The first one creates a delegate object. It may return NULL to indicate an\n",
      " |  error (with a suitable error message reported by calling report_error()).\n",
      " |  The second one destroys delegate object and must be called for every\n",
      " |  created delegate object. Passing NULL as argument value is allowed, i.e.\n",
      " |  \n",
      " |    tflite_plugin_destroy_delegate(tflite_plugin_create_delegate(...))\n",
      " |  \n",
      " |  always works.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  __init__(self, library, options=None)\n",
      " |      Loads delegate from the shared library.\n",
      " |      \n",
      " |      Args:\n",
      " |        library: Shared library name.\n",
      " |        options: Dictionary of options that are required to load the delegate. All\n",
      " |          keys and values in the dictionary should be serializable. Consult the\n",
      " |          documentation of the specific delegate for required and legal options.\n",
      " |          (default None)\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: This is raised if the Python implementation is not CPython.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pycoral.adapters import classify, common\n",
    "from pycoral.utils.edgetpu import make_interpreter\n",
    "import platform\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "_EDGETPU_SHARED_LIB = {\n",
    "  'Linux': 'libedgetpu.so.1',\n",
    "  'Darwin': 'libedgetpu.1.dylib',\n",
    "  'Windows': 'edgetpu.dll'\n",
    "}[platform.system()]\n",
    "\n",
    "print(_EDGETPU_SHARED_LIB)\n",
    "\n",
    "interp = tflite.load_delegate(_EDGETPU_SHARED_LIB)\n",
    "\n",
    "print(help(interp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_mnist784_dataset():\n",
    "    data_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "    mnist_dir =  os.path.join(os.getcwd(), \"datasets\", \"mnist_784\")\n",
    "    if not os.path.exists(mnist_dir):\n",
    "        os.mkdir(mnist_dir)\n",
    "\n",
    "    mnist = fetch_openml('mnist_784', as_frame=False)\n",
    "    data_df = pd.DataFrame(mnist.data, columns=mnist.feature_names)\n",
    "    target_df = pd.DataFrame(mnist.target, columns=mnist.target_names)\n",
    "    data_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_data.csv\")\n",
    "    target_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_target.csv\")\n",
    "    data_df.to_csv(data_path)\n",
    "    target_df.to_csv(target_path)\n",
    "    X, y = mnist.data, mnist.target\n",
    "    return X, y\n",
    "\n",
    "def mnist784_df_from_csv():\n",
    "    data_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_data.csv\")\n",
    "    target_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_target.csv\")\n",
    "    data_df = pd.read_csv(data_path)\n",
    "    target_df = pd.read_csv(target_path)\n",
    "    X_df, y_df = data_df, target_df\n",
    "    X_df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "    y_df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "    return X_df, y_df\n",
    "\n",
    "def train_predict_mnist784():\n",
    "    X_df, y_df = mnist784_df_from_csv()\n",
    "    X = X_df.values\n",
    "    y = y_df.values\n",
    "    some_digit = X[0]\n",
    "    X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "    y_train_5 = (y_train == 5)\n",
    "    y_test_5 = (y_test == 5)\n",
    "    sgd_clf = SGDClassifier(random_state=42)\n",
    "    sgd_clf.fit(X_train, y_train_5)\n",
    "    sgd_clf.predict([some_digit])\n",
    "    scores = cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "    return scores\n",
    "\n",
    "# res = train_predict_mnist784()\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def plot_digit_arr(img_data):\n",
    "    shape = img_data.shape[0]\n",
    "    size = int(shape**0.5)\n",
    "    img = img_data.reshape(size, size)\n",
    "    plt.imshow(img, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def crop_images(paths):\n",
    "    i = 0\n",
    "    img_dir = os.path.join(os.getcwd(), \"datasets\", \"images\")\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "    for path in paths:\n",
    "        i += 1\n",
    "        new_img_path = os.path.join(img_dir, \"img{}.png\".format(i))\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img_data[0:45, 0:278]\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "\n",
    "def split_image_digits(path, imgs_path):\n",
    "    new_dirname = os.path.split(path)[-1].split(\".\")[0]\n",
    "    new_dir = os.path.join(os.getcwd(), \"datasets\", \"new_images\")\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.mkdir(new_dir)\n",
    "    new_path = os.path.join(new_dir, new_dirname)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)\n",
    "    img = cv2.imread(path)\n",
    "    img1 = img[0:44, 0:92]\n",
    "    img2 = img[0:44, 92:184]\n",
    "    img3 = img[0:44, 184:276]\n",
    "    cv2.imwrite(os.path.join(new_path, \"image1.png\"), img1)\n",
    "    cv2.imwrite(os.path.join(new_path, \"image2.png\"), img2)\n",
    "    cv2.imwrite(os.path.join(new_path, \"image3.png\"), img3)\n",
    "    return new_path\n",
    "\n",
    "def create_image_data(img_dirname):\n",
    "    new_image_paths = []\n",
    "    images_dir = os.path.join(os.getcwd(), \"datasets\", img_dirname)\n",
    "    paths = [[os.path.join(dn, fn) for fn in files] for dn, _ , files in os.walk(images_dir)]\n",
    "    paths = sum(paths, [])\n",
    "    crop_images(paths)\n",
    "    for path in paths:\n",
    "        new_path = split_image_digits(path, images_dir)\n",
    "        new_image_paths.append(new_path)\n",
    "    return new_image_paths\n",
    "    \n",
    "def preprocess_image_data(image_path, n):\n",
    "    new_images = [os.path.join(image_path, fn) for fn in os.listdir(image_path)]\n",
    "    img1 = cv2.imread(new_images[0], cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(new_images[1], cv2.IMREAD_GRAYSCALE)\n",
    "    img3 = cv2.imread(new_images[2], cv2.IMREAD_GRAYSCALE)\n",
    "    imgs = [img1.flatten(), img2.flatten(), img3.flatten()]\n",
    "    dfs = {}\n",
    "    for i in range(len(imgs)):\n",
    "        img = imgs[i]\n",
    "        name = \"image{}\".format((i+1)+n)\n",
    "        df = img_to_dict(img)\n",
    "        dfs[name] = df\n",
    "    return dfs\n",
    "\n",
    "def img_to_dict(img):\n",
    "    p = 0\n",
    "    res = {}\n",
    "    for i in range(img.shape[0]):\n",
    "        p += 1\n",
    "        col = \"pixel{}\".format(p)\n",
    "        pix = img[i]\n",
    "        res[col] = pix\n",
    "    return res\n",
    "\n",
    "def images_to_df(img_path, n):\n",
    "    dfs = preprocess_image_data(img_path, n)\n",
    "    main_df = pd.DataFrame(dfs.values(), index=dfs.keys())\n",
    "    return main_df\n",
    "\n",
    "def save_image_data(imgs_path):\n",
    "    dfs = []\n",
    "    n = 0\n",
    "    for img_name in os.listdir(imgs_path):\n",
    "        img_path = os.path.join(imgs_path, img_name)\n",
    "        df = images_to_df(img_path, n)\n",
    "        dfs.append(df)\n",
    "        n += 3\n",
    "    main_df = pd.DataFrame()\n",
    "    for df in dfs:\n",
    "        if len(main_df) == 0:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = pd.concat([main_df, df])\n",
    "    df_save_dir = os.path.join(os.getcwd(), \"output\")\n",
    "    if not os.path.exists(df_save_dir):\n",
    "        os.mkdir(df_save_dir)\n",
    "    main_df.to_csv(os.path.join(df_save_dir, \"image_pixels_{}.csv\".format(int(time.time()))))\n",
    "    return main_df\n",
    "    \n",
    "def train_predict_digits(X, y, digit=1):\n",
    "    X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "    y_train_digit = (y_train == digit)\n",
    "    y_test_digit = (y_test == digit)\n",
    "    sgd_clf = SGDClassifier(random_state=42)\n",
    "    sgd_clf.fit(X_train, y_train_digit)\n",
    "    sgd_clf.predict(X_test[0])\n",
    "    scores = cross_val_score(sgd_clf, X_train, y_train_digit, cv=3, scoring=\"accuracy\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path_list = create_image_data(\"images\")\n",
    "new_path = os.path.join(os.getcwd(), \"datasets\", \"new_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = save_image_data(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4048)\n",
      "(35, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "orig_targets = [\"89\", \"121\", \"28\", \"81\", \"119\", \"28\", \"86\", \"121\", \"33\", \"85\", \"121\", \"32\", \"84\", \"33\", \"82\", \"120\", \"30\", \"82\", \"120\", \"30\", \"82\", \"121\", \"49\", \"81\", \"118\", \"60\", \"69\", \"123\", \"57\", \"72\", \"121\", \"30\", \"89\", \"121\", \"28\", ]\n",
    "targets = [int(i) for i in orig_targets]\n",
    "name = \"image{}\"\n",
    "image_idxs = []\n",
    "\n",
    "for i in range(1, 30):\n",
    "    image_idxs.append(name.format(i))\n",
    "\n",
    "\n",
    "X_train = np.array(df.loc[image_idxs].values)\n",
    "y_train = np.array([[x] for x in targets])\n",
    "print(X_train[:20].shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.85714286 0.83333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\py_repos\\image_classifier\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\py_repos\\image_classifier\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\py_repos\\image_classifier\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\py_repos\\image_classifier\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "def train_predict_digits(X, y, digit=121):\n",
    "    X_train, X_test, y_train, y_test = X[:20], X[20:], y[:20], y[20:]\n",
    "    y_train_digit = (y_train == digit)\n",
    "    y_test_digit = (y_test == digit)\n",
    "    sgd_clf = SGDClassifier(random_state=42)\n",
    "    sgd_clf.fit(X_train, y_train_digit)\n",
    "    sgd_clf.predict([X_test[0]])\n",
    "    scores = cross_val_score(sgd_clf, X_train, y_train_digit, cv=3, scoring=\"accuracy\")\n",
    "    return scores\n",
    "\n",
    "\n",
    "res = train_predict_digits(X_train, y_train)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2395 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 271us/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 669.2395 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 669.2394 - accuracy: 0.0000e+00\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "UNITS = 5\n",
    "EPOCHS = 100\n",
    "\n",
    "X = X_train\n",
    "y = y_train\n",
    "num_classes = len(y)\n",
    "img_height = 45\n",
    "img_width = 278\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:20], X[20:], y[:20], y[20:]\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(UNITS, activation=tf.nn.relu, input_shape=(4048,)),\n",
    "    tf.keras.layers.Dense(UNITS, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='sgd',\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "res = model.fit(X_train, y_train, epochs=EPOCHS)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(f\"Loss: {scores[0]}\")\n",
    "# print(f\"Accuracy: {scores[0]}\")\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
