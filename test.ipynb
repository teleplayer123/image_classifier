{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edgetpu.dll\n",
      "Help on Delegate in module tflite_runtime.interpreter object:\n",
      "\n",
      "class Delegate(builtins.object)\n",
      " |  Delegate(library, options=None)\n",
      " |  \n",
      " |  Python wrapper class to manage TfLiteDelegate objects.\n",
      " |  \n",
      " |  The shared library is expected to have two functions:\n",
      " |    TfLiteDelegate* tflite_plugin_create_delegate(\n",
      " |        char**, char**, size_t, void (*report_error)(const char *))\n",
      " |    void tflite_plugin_destroy_delegate(TfLiteDelegate*)\n",
      " |  \n",
      " |  The first one creates a delegate object. It may return NULL to indicate an\n",
      " |  error (with a suitable error message reported by calling report_error()).\n",
      " |  The second one destroys delegate object and must be called for every\n",
      " |  created delegate object. Passing NULL as argument value is allowed, i.e.\n",
      " |  \n",
      " |    tflite_plugin_destroy_delegate(tflite_plugin_create_delegate(...))\n",
      " |  \n",
      " |  always works.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  __init__(self, library, options=None)\n",
      " |      Loads delegate from the shared library.\n",
      " |      \n",
      " |      Args:\n",
      " |        library: Shared library name.\n",
      " |        options: Dictionary of options that are required to load the delegate. All\n",
      " |          keys and values in the dictionary should be serializable. Consult the\n",
      " |          documentation of the specific delegate for required and legal options.\n",
      " |          (default None)\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: This is raised if the Python implementation is not CPython.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pycoral.adapters import classify, common\n",
    "from pycoral.utils.edgetpu import make_interpreter\n",
    "import platform\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "_EDGETPU_SHARED_LIB = {\n",
    "  'Linux': 'libedgetpu.so.1',\n",
    "  'Darwin': 'libedgetpu.1.dylib',\n",
    "  'Windows': 'edgetpu.dll'\n",
    "}[platform.system()]\n",
    "\n",
    "print(_EDGETPU_SHARED_LIB)\n",
    "\n",
    "interp = tflite.load_delegate(_EDGETPU_SHARED_LIB)\n",
    "\n",
    "print(help(interp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_mnist784_dataset():\n",
    "    data_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "    mnist_dir =  os.path.join(os.getcwd(), \"datasets\", \"mnist_784\")\n",
    "    if not os.path.exists(mnist_dir):\n",
    "        os.mkdir(mnist_dir)\n",
    "\n",
    "    mnist = fetch_openml('mnist_784', as_frame=False)\n",
    "    data_df = pd.DataFrame(mnist.data, columns=mnist.feature_names)\n",
    "    target_df = pd.DataFrame(mnist.target, columns=mnist.target_names)\n",
    "    data_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_data.csv\")\n",
    "    target_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_target.csv\")\n",
    "    data_df.to_csv(data_path)\n",
    "    target_df.to_csv(target_path)\n",
    "    X, y = mnist.data, mnist.target\n",
    "    return X, y\n",
    "\n",
    "def mnist784_df_from_csv():\n",
    "    data_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_data.csv\")\n",
    "    target_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_target.csv\")\n",
    "    data_df = pd.read_csv(data_path)\n",
    "    target_df = pd.read_csv(target_path)\n",
    "    X_df, y_df = data_df, target_df\n",
    "    X_df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "    y_df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "    return X_df, y_df\n",
    "\n",
    "def train_predict_mnist784():\n",
    "    X_df, y_df = mnist784_df_from_csv()\n",
    "    X = X_df.values\n",
    "    y = y_df.values\n",
    "    some_digit = X[0]\n",
    "    X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "    y_train_5 = (y_train == 5)\n",
    "    y_test_5 = (y_test == 5)\n",
    "    sgd_clf = SGDClassifier(random_state=42)\n",
    "    sgd_clf.fit(X_train, y_train_5)\n",
    "    sgd_clf.predict([some_digit])\n",
    "    scores = cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "    return scores\n",
    "\n",
    "# res = train_predict_mnist784()\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def plot_digit_arr(img_data):\n",
    "    shape = img_data.shape[0]\n",
    "    size = int(shape**0.5)\n",
    "    img = img_data.reshape(size, size)\n",
    "    plt.imshow(img, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def crop_images(paths):\n",
    "    i = 0\n",
    "    img_dir = os.path.join(os.getcwd(), \"datasets\", \"images\")\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "    for path in paths:\n",
    "        i += 1\n",
    "        new_img_path = os.path.join(img_dir, \"img{}.png\".format(i))\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img_data[0:45, 0:278]\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "\n",
    "def split_image_digits(path, imgs_path):\n",
    "    new_dirname = os.path.split(path)[-1].split(\".\")[0]\n",
    "    new_dir = os.path.join(os.getcwd(), \"datasets\", \"new_images\")\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.mkdir(new_dir)\n",
    "    new_path = os.path.join(new_dir, new_dirname)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)\n",
    "    img = cv2.imread(path)\n",
    "    img1 = img[0:44, 0:92]\n",
    "    img2 = img[0:44, 92:184]\n",
    "    img3 = img[0:44, 184:276]\n",
    "    cv2.imwrite(os.path.join(new_path, \"image1.png\"), img1)\n",
    "    cv2.imwrite(os.path.join(new_path, \"image2.png\"), img2)\n",
    "    cv2.imwrite(os.path.join(new_path, \"image3.png\"), img3)\n",
    "    return new_path\n",
    "\n",
    "def create_image_data(img_dirname):\n",
    "    new_image_paths = []\n",
    "    images_dir = os.path.join(os.getcwd(), \"datasets\", img_dirname)\n",
    "    paths = [[os.path.join(dn, fn) for fn in files] for dn, _ , files in os.walk(images_dir)]\n",
    "    paths = sum(paths, [])\n",
    "    crop_images(paths)\n",
    "    for path in paths:\n",
    "        new_path = split_image_digits(path, images_dir)\n",
    "        new_image_paths.append(new_path)\n",
    "    return new_image_paths\n",
    "    \n",
    "def preprocess_image_data(image_path, n):\n",
    "    new_images = [os.path.join(image_path, fn) for fn in os.listdir(image_path)]\n",
    "    img1 = cv2.imread(new_images[0], cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(new_images[1], cv2.IMREAD_GRAYSCALE)\n",
    "    img3 = cv2.imread(new_images[2], cv2.IMREAD_GRAYSCALE)\n",
    "    imgs = [img1.flatten(), img2.flatten(), img3.flatten()]\n",
    "    dfs = {}\n",
    "    for i in range(len(imgs)):\n",
    "        img = imgs[i]\n",
    "        name = \"image{}\".format((i+1)+n)\n",
    "        df = img_to_dict(img)\n",
    "        dfs[name] = df\n",
    "    return dfs\n",
    "\n",
    "def img_to_dict(img):\n",
    "    p = 0\n",
    "    res = {}\n",
    "    for i in range(img.shape[0]):\n",
    "        p += 1\n",
    "        col = \"pixel{}\".format(p)\n",
    "        pix = img[i]\n",
    "        res[col] = pix\n",
    "    return res\n",
    "\n",
    "def images_to_df(img_path, n):\n",
    "    dfs = preprocess_image_data(img_path, n)\n",
    "    main_df = pd.DataFrame(dfs.values(), index=dfs.keys())\n",
    "    return main_df\n",
    "\n",
    "def save_image_data(imgs_path):\n",
    "    dfs = []\n",
    "    n = 0\n",
    "    for img_name in os.listdir(imgs_path):\n",
    "        img_path = os.path.join(imgs_path, img_name)\n",
    "        df = images_to_df(img_path, n)\n",
    "        dfs.append(df)\n",
    "        n += 3\n",
    "    main_df = pd.DataFrame()\n",
    "    for df in dfs:\n",
    "        if len(main_df) == 0:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = pd.concat([main_df, df])\n",
    "    df_save_dir = os.path.join(os.getcwd(), \"output\")\n",
    "    if not os.path.exists(df_save_dir):\n",
    "        os.mkdir(df_save_dir)\n",
    "    main_df.to_csv(os.path.join(df_save_dir, \"image_pixels_{}.csv\".format(int(time.time()))))\n",
    "    \n",
    "def train_predict_digits(X, y, digit=1):\n",
    "    X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "    y_train_digit = (y_train == digit)\n",
    "    y_test_digit = (y_test == digit)\n",
    "    sgd_clf = SGDClassifier(random_state=42)\n",
    "    sgd_clf.fit(X_train, y_train_digit)\n",
    "    sgd_clf.predict(X_test[0])\n",
    "    scores = cross_val_score(sgd_clf, X_train, y_train_digit, cv=3, scoring=\"accuracy\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = create_image_data(\"images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
