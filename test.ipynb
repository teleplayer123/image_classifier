{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycoral.adapters import classify, common\n",
    "# from pycoral.utils.edgetpu import make_interpreter\n",
    "# import platform\n",
    "# import tflite_runtime.interpreter as tflite\n",
    "\n",
    "# _EDGETPU_SHARED_LIB = {\n",
    "#   'Linux': 'libedgetpu.so.1',\n",
    "#   'Darwin': 'libedgetpu.1.dylib',\n",
    "#   'Windows': 'edgetpu.dll'\n",
    "# }[platform.system()]\n",
    "\n",
    "# print(_EDGETPU_SHARED_LIB)\n",
    "\n",
    "# interp = tflite.load_delegate(_EDGETPU_SHARED_LIB)\n",
    "\n",
    "# print(help(interp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_mnist784_dataset():\n",
    "    data_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "    mnist_dir =  os.path.join(os.getcwd(), \"datasets\", \"mnist_784\")\n",
    "    if not os.path.exists(mnist_dir):\n",
    "        os.mkdir(mnist_dir)\n",
    "\n",
    "    mnist = fetch_openml('mnist_784', as_frame=False)\n",
    "    data_df = pd.DataFrame(mnist.data, columns=mnist.feature_names)\n",
    "    target_df = pd.DataFrame(mnist.target, columns=mnist.target_names)\n",
    "    data_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_data.csv\")\n",
    "    target_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_target.csv\")\n",
    "    data_df.to_csv(data_path)\n",
    "    target_df.to_csv(target_path)\n",
    "    X, y = mnist.data, mnist.target\n",
    "    return X, y\n",
    "\n",
    "def mnist784_df_from_csv():\n",
    "    data_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_data.csv\")\n",
    "    target_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_target.csv\")\n",
    "    data_df = pd.read_csv(data_path)\n",
    "    target_df = pd.read_csv(target_path)\n",
    "    X_df, y_df = data_df, target_df\n",
    "    X_df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "    y_df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "    return X_df, y_df\n",
    "\n",
    "def train_predict_mnist784():\n",
    "    X_df, y_df = mnist784_df_from_csv()\n",
    "    X = X_df.values\n",
    "    y = y_df.values\n",
    "    some_digit = X[0]\n",
    "    X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "    y_train_5 = (y_train == 5)\n",
    "    y_test_5 = (y_test == 5)\n",
    "    sgd_clf = SGDClassifier(random_state=42)\n",
    "    sgd_clf.fit(X_train, y_train_5)\n",
    "    sgd_clf.predict([some_digit])\n",
    "    scores = cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "    return scores\n",
    "\n",
    "# res = train_predict_mnist784()\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def plot_digit_arr(img_data):\n",
    "    shape = img_data.shape[0]\n",
    "    size = int(shape**0.5)\n",
    "    img = img_data.reshape(size, size)\n",
    "    plt.imshow(img, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def crop_images(paths):\n",
    "    i = 0\n",
    "    img_dir = os.path.join(os.getcwd(), \"datasets\", \"images\")\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "    for path in paths:\n",
    "        i += 1\n",
    "        new_img_path = os.path.join(img_dir, \"img{}.png\".format(i))\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img_data[0:45, 0:278]\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "\n",
    "def split_image_digits(path, imgs_path):\n",
    "    new_dirname = os.path.split(path)[-1].split(\".\")[0]\n",
    "    new_dir = os.path.join(os.getcwd(), \"datasets\", \"new_images\")\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.mkdir(new_dir)\n",
    "    new_path = os.path.join(new_dir, new_dirname)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)\n",
    "    img = cv2.imread(path)\n",
    "    img1 = img[0:44, 0:92]\n",
    "    img2 = img[0:44, 92:184]\n",
    "    img3 = img[0:44, 184:276]\n",
    "    cv2.imwrite(os.path.join(new_path, \"image1.png\"), img1)\n",
    "    cv2.imwrite(os.path.join(new_path, \"image2.png\"), img2)\n",
    "    cv2.imwrite(os.path.join(new_path, \"image3.png\"), img3)\n",
    "    return new_path\n",
    "\n",
    "def create_image_data(img_dirname):\n",
    "    new_image_paths = []\n",
    "    images_dir = os.path.join(os.getcwd(), \"datasets\", img_dirname)\n",
    "    paths = [[os.path.join(dn, fn) for fn in files] for dn, _ , files in os.walk(images_dir)]\n",
    "    paths = sum(paths, [])\n",
    "    crop_images(paths)\n",
    "    for path in paths:\n",
    "        new_path = split_image_digits(path, images_dir)\n",
    "        new_image_paths.append(new_path)\n",
    "    return new_image_paths\n",
    "    \n",
    "def preprocess_image_data(image_path, n):\n",
    "    new_images = [os.path.join(image_path, fn) for fn in os.listdir(image_path)]\n",
    "    img1 = cv2.imread(new_images[0], cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(new_images[1], cv2.IMREAD_GRAYSCALE)\n",
    "    img3 = cv2.imread(new_images[2], cv2.IMREAD_GRAYSCALE)\n",
    "    imgs = [img1.flatten(), img2.flatten(), img3.flatten()]\n",
    "    dfs = {}\n",
    "    for i in range(len(imgs)):\n",
    "        img = imgs[i]\n",
    "        name = \"image{}\".format((i+1)+n)\n",
    "        df = img_to_dict(img)\n",
    "        dfs[name] = df\n",
    "    return dfs\n",
    "\n",
    "def img_to_dict(img):\n",
    "    p = 0\n",
    "    res = {}\n",
    "    for i in range(img.shape[0]):\n",
    "        p += 1\n",
    "        col = \"pixel{}\".format(p)\n",
    "        pix = img[i]\n",
    "        res[col] = pix\n",
    "    return res\n",
    "\n",
    "def images_to_df(img_path, n):\n",
    "    dfs = preprocess_image_data(img_path, n)\n",
    "    main_df = pd.DataFrame(dfs.values(), index=dfs.keys())\n",
    "    return main_df\n",
    "\n",
    "def save_image_data(imgs_path):\n",
    "    dfs = []\n",
    "    n = 0\n",
    "    for img_name in os.listdir(imgs_path):\n",
    "        img_path = os.path.join(imgs_path, img_name)\n",
    "        df = images_to_df(img_path, n)\n",
    "        dfs.append(df)\n",
    "        n += 3\n",
    "    main_df = pd.DataFrame()\n",
    "    for df in dfs:\n",
    "        if len(main_df) == 0:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = pd.concat([main_df, df])\n",
    "    df_save_dir = os.path.join(os.getcwd(), \"output\")\n",
    "    if not os.path.exists(df_save_dir):\n",
    "        os.mkdir(df_save_dir)\n",
    "    main_df.to_csv(os.path.join(df_save_dir, \"image_pixels_{}.csv\".format(int(time.time()))))\n",
    "    return main_df\n",
    "    \n",
    "def train_predict_digits(X, y, digit=1):\n",
    "    X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "    y_train_digit = (y_train == digit)\n",
    "    y_test_digit = (y_test == digit)\n",
    "    sgd_clf = SGDClassifier(random_state=42)\n",
    "    sgd_clf.fit(X_train, y_train_digit)\n",
    "    sgd_clf.predict(X_test[0])\n",
    "    scores = cross_val_score(sgd_clf, X_train, y_train_digit, cv=3, scoring=\"accuracy\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path_list = create_image_data(\"images\")\n",
    "new_path = os.path.join(os.getcwd(), \"datasets\", \"new_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = save_image_data(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4048)\n",
      "(20, 1)\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "orig_targets = [\"89\", \"121\", \"28\", \"81\", \"119\", \"28\", \"86\", \"121\", \"33\", \"85\", \"121\", \"32\", \"84\", \"33\", \"82\", \"120\", \"30\", \"82\", \"120\", \"30\", \"82\", \"121\", \"49\", \"81\", \"118\", \"60\", \"69\", \"123\", \"57\", \"72\", \"121\", \"30\", \"89\", \"121\", \"28\", ]\n",
    "targets = [int(i) for i in orig_targets]\n",
    "name = \"image{}\"\n",
    "image_idxs = []\n",
    "\n",
    "for i in range(1, 30):\n",
    "    image_idxs.append(name.format(i))\n",
    "\n",
    "\n",
    "X_train_main = np.array(df.loc[image_idxs].values)\n",
    "y_train_main = np.array([[x] for x in targets])\n",
    "print(X_train_main[:20].shape)\n",
    "print(y_train_main[:20].shape)\n",
    "print(len(orig_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85714286 0.85714286 0.83333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\py_repos\\image_classifier\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\py_repos\\image_classifier\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\py_repos\\image_classifier\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\py_repos\\image_classifier\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "def train_predict_digits(X, y, digit=121):\n",
    "    X_train, X_test, y_train, y_test = X[:20], X[20:], y[:20], y[20:]\n",
    "    y_train_digit = (y_train == digit)\n",
    "    y_test_digit = (y_test == digit)\n",
    "    sgd_clf = SGDClassifier(random_state=42)\n",
    "    sgd_clf.fit(X_train, y_train_digit)\n",
    "    sgd_clf.predict([X_test[0]])\n",
    "    scores = cross_val_score(sgd_clf, X_train, y_train_digit, cv=3, scoring=\"accuracy\")\n",
    "    return scores\n",
    "\n",
    "\n",
    "res = train_predict_digits(X_train_main, y_train_main)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel1       112\n",
       "pixel2       112\n",
       "pixel3       112\n",
       "pixel4         0\n",
       "pixel5         1\n",
       "            ... \n",
       "pixel4044     51\n",
       "pixel4045     54\n",
       "pixel4046     28\n",
       "pixel4047      2\n",
       "pixel4048      0\n",
       "Name: image1, Length: 4048, dtype: uint8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\"image1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 2.2989 - accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1135 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9253 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7197 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4997 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2696 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0388 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8168 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6135 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4386 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1934 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1214 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0745 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0453 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Loss: 0.0028536426834762096\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "UNITS = 5\n",
    "EPOCHS = 20\n",
    "\n",
    "X = X_train_main\n",
    "y = y_train_main\n",
    "num_classes = len(y)\n",
    "img_height = 45\n",
    "img_width = 278\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:20], X[20:25], y[:20], y[20:25]\n",
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)\n",
    "y_train = tf.keras.utils.normalize(y_train, axis=1)\n",
    "y_test = tf.keras.utils.normalize(y_test, axis=1)\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(UNITS, activation=tf.nn.relu, input_shape=(4048,)),\n",
    "    tf.keras.layers.Dense(UNITS, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='sgd',\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #model.add(tf.keras.layers.Flatten(input_shape=(4048,)))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    #model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "res = model.fit(X_train, y_train, epochs=EPOCHS)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Loss: {scores[0]}\")\n",
    "print(f\"Accuracy: {scores[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 76.6851 - accuracy: 0.0000e+00\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 80.1977 - accuracy: 0.0000e+00\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 81.6339 - accuracy: 0.0000e+00\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 69.3393 - accuracy: 0.0000e+00\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 41.4612 - accuracy: 0.0000e+00\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 30.2389 - accuracy: 0.0000e+00\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 22.8942 - accuracy: 0.0000e+00\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.4447 - accuracy: 0.1000\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 11.8866 - accuracy: 0.0500\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.6102 - accuracy: 0.2000\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.4797 - accuracy: 0.2000\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4125 - accuracy: 0.4000\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.6808 - accuracy: 0.2000\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3035 - accuracy: 0.2000\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.4033 - accuracy: 0.5000\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7407 - accuracy: 0.3500\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.8538 - accuracy: 0.3000\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4414 - accuracy: 0.3000\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2887 - accuracy: 0.4500\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3777 - accuracy: 0.3500\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2291 - accuracy: 0.5000\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0485 - accuracy: 0.6000\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1879 - accuracy: 0.5500\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1486 - accuracy: 0.5000\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2853 - accuracy: 0.5500\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1276 - accuracy: 0.6000\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1420 - accuracy: 0.5000\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9583 - accuracy: 0.6000\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7563 - accuracy: 0.6500\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8359 - accuracy: 0.6000\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6987 - accuracy: 0.6000\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6426 - accuracy: 0.7500\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6467 - accuracy: 0.7000\n",
      "Epoch 34/60\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5833 - accuracy: 0.7000\n",
      "Epoch 35/60\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6105 - accuracy: 0.7500\n",
      "Epoch 36/60\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5342 - accuracy: 0.7500\n",
      "Epoch 37/60\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5415 - accuracy: 0.7500\n",
      "Epoch 38/60\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5275 - accuracy: 0.7500\n",
      "Epoch 39/60\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4650 - accuracy: 0.7500\n",
      "Epoch 40/60\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4949 - accuracy: 0.8000\n",
      "Epoch 41/60\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4956 - accuracy: 0.8000\n",
      "Epoch 42/60\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4350 - accuracy: 0.8000\n",
      "Epoch 43/60\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.8500\n",
      "Epoch 44/60\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4648 - accuracy: 0.7500\n",
      "Epoch 45/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4277 - accuracy: 0.7500\n",
      "Epoch 46/60\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.8500\n",
      "Epoch 47/60\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8500\n",
      "Epoch 48/60\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4108 - accuracy: 0.7500\n",
      "Epoch 49/60\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4249 - accuracy: 0.8500\n",
      "Epoch 50/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4030 - accuracy: 0.8500\n",
      "Epoch 51/60\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4102 - accuracy: 0.7500\n",
      "Epoch 52/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3994 - accuracy: 0.8500\n",
      "Epoch 53/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3828 - accuracy: 0.9000\n",
      "Epoch 54/60\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3993 - accuracy: 0.8500\n",
      "Epoch 55/60\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8000\n",
      "Epoch 56/60\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3862 - accuracy: 0.9000\n",
      "Epoch 57/60\n",
      "1/1 [==============================] - 0s 338us/step - loss: 0.3822 - accuracy: 0.8500\n",
      "Epoch 58/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3736 - accuracy: 0.9000\n",
      "Epoch 59/60\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3788 - accuracy: 0.8500\n",
      "Epoch 60/60\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8500\n",
      "Loss: 34.35248947143555\n",
      "Accuracy: 0.20000000298023224\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "\n",
    "UNITS = 5\n",
    "EPOCHS = 60\n",
    "\n",
    "X = X_train_main\n",
    "y = y_train_main\n",
    "num_classes = len(y)\n",
    "img_height = 45\n",
    "img_width = 278\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:20], X[20:25], y[:20], y[20:25]\n",
    "\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(UNITS, activation=tf.nn.relu, input_shape=(4048,)),\n",
    "    tf.keras.layers.Dense(UNITS, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='sgd',\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(4048,)))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1000, activation='softmax'))\n",
    "    #model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "res = model.fit(X_train, y_train, epochs=EPOCHS)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Loss: {scores[0]}\")\n",
    "print(f\"Accuracy: {scores[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# print(\"Loss : \", loss)\n",
    "# print(\"Accuracy : \", accuracy)\n",
    "print(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
