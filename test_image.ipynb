{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\py_repos\\image_classifier\\datasets\\newer_images\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_digit_arr(img_data):\n",
    "    shape = img_data.shape[0]\n",
    "    size = int(shape**0.5)\n",
    "    img = img_data.reshape(size, size)\n",
    "    plt.imshow(img, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def split_image_digits(path):\n",
    "    img = cv2.imread(path)\n",
    "    img1 = img[0:44, 0:92]\n",
    "    img2 = img[0:44, 92:184]\n",
    "    img3 = img[0:44, 184:276]\n",
    "    # img1 = img1.reshape(-1, 4048).astype(np.int8)\n",
    "    # img2 = img2.reshape(-1, 4048).astype(np.int8)\n",
    "    # img3 = img3.reshape(-1, 4048).astype(np.int8)\n",
    "    return img1, img2, img3\n",
    "\n",
    "def crop_images(paths):\n",
    "    i = 0\n",
    "    img_dir = os.path.join(os.getcwd(), \"datasets\", \"images\")\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "    for path in paths:\n",
    "        i += 1\n",
    "        new_img_path = os.path.join(img_dir, \"img{}.png\".format(i))\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img_data[0:45, 0:278]\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "\n",
    "def create_image_data(img_dirname, outdirname=\"newer_images\"):\n",
    "    images_dir = os.path.join(os.getcwd(), \"datasets\", img_dirname)\n",
    "    outdir = os.path.join(os.getcwd(), \"datasets\", outdirname)\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    paths = [[os.path.join(dn, fn) for fn in files] for dn, _ , files in os.walk(images_dir)]\n",
    "    paths = sum(paths, [])\n",
    "    crop_images(paths)\n",
    "    i = 0\n",
    "    for path in paths:\n",
    "        img1, img2, img3 = split_image_digits(path)\n",
    "        path1 = os.path.join(outdir, \"image{}.png\".format(i+1))\n",
    "        path2 = os.path.join(outdir, \"image{}.png\".format(i+2))\n",
    "        path3 = os.path.join(outdir, \"image{}.png\".format(i+3))\n",
    "        cv2.imwrite(path1, img1)\n",
    "        cv2.imwrite(path2, img2)\n",
    "        cv2.imwrite(path3, img3)\n",
    "        i += 3\n",
    "    return outdir\n",
    "\n",
    "img1_path = os.path.join(os.getcwd(), \"datasets\", \"images\", \"img1.png\")\n",
    "\n",
    "new_path = create_image_data(\"images\")\n",
    "print(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 92)\n",
      "(198, 44, 92)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def normalize_img(img):\n",
    "    img = img * 1.0/255\n",
    "    return img\n",
    "\n",
    "def imgs_to_dict(dirname):\n",
    "    img_dict = {}\n",
    "    image_dir = os.path.join(os.getcwd(), \"datasets\", dirname)\n",
    "    i = 0\n",
    "    for fname in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, fname)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_dict[\"image{}\".format(i+1)] = img\n",
    "        i += 1\n",
    "    return img_dict\n",
    "\n",
    "def images_to_arr(obj):\n",
    "    imgs = []\n",
    "    if isinstance(obj, dict):\n",
    "        imgs = [normalize_img(img) for img in obj.values()]\n",
    "    elif isinstance(obj, str):\n",
    "        dir_path = None \n",
    "        if os.path.isdir(imgs):\n",
    "            dir_path = imgs\n",
    "        else:\n",
    "            dir_path = os.path.join(os.getcwd(), obj)\n",
    "        for fname in os.listdir(dir_path):\n",
    "            img_path = os.path.join(dir_path, fname)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = normalize_img(img)\n",
    "            imgs.append(img)\n",
    "    else:\n",
    "        raise TypeError(f\"type {type(obj)} is not supported\")\n",
    "    return np.array(imgs)\n",
    "\n",
    "\n",
    "d = imgs_to_dict(\"newer_images\")\n",
    "print(d[\"image1\"].shape)\n",
    "\n",
    "a = images_to_arr(d)\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 92)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa7d363640>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image_dir = os.path.join(os.getcwd(), \"datasets\", \"newer_images\")\n",
    "img1_path = os.path.join(image_dir, \"image40.png\")\n",
    "img1 = cv2.imread(img1_path)\n",
    "img1 = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(img1.shape)\n",
    "\n",
    "plt.imshow(img1, cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "orig_targets = [\"89\", \"121\", \"28\", \"85\", \"120\", \"30\", \"81\", \"120\", \"45\", \"90\", \"121\", \"34\", \"85\", \"122\", \"31\", \"78\", \"120\", \"31\", \"77\", \"113\", \"27\", \"62\", \"120\", \"32\", \"62\", \"120\", \"32\", \"62\", \"120\", \"32\", \"90\", \"120\", \"28\", \"90\", \"121\", \"34\", \"60\", \"120\", \"29\", \"76\"]\n",
    "targets = [int(i) for i in orig_targets]\n",
    "name = \"image{}\"\n",
    "image_idxs = []\n",
    "\n",
    "for i in range(len(targets)):\n",
    "    image_idxs.append(name.format(i+1))\n",
    "\n",
    "fname = os.path.join(os.getcwd(), \"datasets\", \"newer_images\", \"labels.txt\")\n",
    "with open(fname, \"w\") as fh:\n",
    "    for k, v in zip(image_idxs, targets):\n",
    "        fh.write(f\"{k}:{v}\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(44, 92)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "\n",
    "# Optional: You can replace the dense layer above with the convolution layers below to get higher accuracy.\n",
    "    # keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "    # keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=tf.nn.relu),\n",
    "    # keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.nn.relu),\n",
    "    # keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # keras.layers.Dropout(0.25),\n",
    "    # keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    # keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2000)\n",
      "(50, 100, 20, 20)\n",
      "\n",
      "\n",
      "(2500, 400)\n",
      "(2500, 400)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    " \n",
    "img_path = os.path.join(os.getcwd(), \"datasets\", \"digits\", \"digits.png\")\n",
    "img = cv.imread(img_path)\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "cells = [np.hsplit(row,100) for row in np.vsplit(gray,50)]\n",
    "x = np.array(cells)\n",
    "train = x[:,:50].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    "test = x[:,50:100].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    "print(gray.shape)\n",
    "print(x.shape)\n",
    "print(\"\\n\")\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    " \n",
    "img_path = os.path.join(os.getcwd(), \"datasets\", \"digits\", \"digits.png\")\n",
    "img = cv.imread(img_path)\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    " \n",
    "# Now we split the image to 5000 cells, each 20x20 size\n",
    "cells = [np.hsplit(row,100) for row in np.vsplit(gray,50)]\n",
    " \n",
    "# Make it into a Numpy array: its size will be (50,100,20,20)\n",
    "x = np.array(cells)\n",
    " \n",
    "# Now we prepare the training data and test data\n",
    "train = x[:,:50].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    "test = x[:,50:100].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    " \n",
    "# Create labels for train and test data\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k,250)[:,np.newaxis]\n",
    "test_labels = train_labels.copy()\n",
    " \n",
    "# Initiate kNN, train it on the training data, then test it with the test data with k=1\n",
    "knn = cv.ml.KNearest_create()\n",
    "knn.train(train, cv.ml.ROW_SAMPLE, train_labels)\n",
    "ret,result,neighbours,dist = knn.findNearest(test,k=5)\n",
    " \n",
    "# Now we check the accuracy of classification\n",
    "# For that, compare the result with test_labels and check which are wrong\n",
    "matches = result==test_labels\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = correct*100.0/result.size\n",
    "print( accuracy )\n",
    "\n",
    "# Save the data\n",
    "np.savez('knn_data.npz',train=train, train_labels=train_labels)\n",
    " \n",
    "# Now load the data\n",
    "with np.load('knn_data.npz') as data:\n",
    "    print( data.files )\n",
    "    train = data['train']\n",
    "    train_labels = data['train_labels']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
