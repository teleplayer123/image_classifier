{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def plot_digit_arr(img_data):\n",
    "    shape = img_data.shape[0]\n",
    "    size = int(shape**0.5)\n",
    "    img = img_data.reshape(size, size)\n",
    "    plt.imshow(img, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def crop_images(paths):\n",
    "    i = 0\n",
    "    img_dir = os.path.join(os.getcwd(), \"datasets\", \"images\")\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "    for path in paths:\n",
    "        i += 1\n",
    "        new_img_path = os.path.join(img_dir, \"img{}.png\".format(i))\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img_data[0:45, 0:278]\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "\n",
    "def split_image_digits(path, out_dir=\"newer_images\"):\n",
    "    new_dirname = os.path.split(path)[-1].split(\".\")[0]\n",
    "    new_dir = os.path.join(os.getcwd(), \"datasets\", out_dir)\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.mkdir(new_dir)\n",
    "    new_path = os.path.join(new_dir, new_dirname)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)\n",
    "    img = cv2.imread(path)\n",
    "    img1 = img[0:44, 0:92]\n",
    "    img2 = img[0:44, 92:184]\n",
    "    img3 = img[0:44, 184:276]\n",
    "    cv2.imwrite(os.path.join(new_path, \"image1.png\"), img1)\n",
    "    cv2.imwrite(os.path.join(new_path, \"image2.png\"), img2)\n",
    "    cv2.imwrite(os.path.join(new_path, \"image3.png\"), img3)\n",
    "    return new_path\n",
    "\n",
    "def create_image_data(img_dirname):\n",
    "    new_image_paths = []\n",
    "    images_dir = os.path.join(os.getcwd(), \"datasets\", img_dirname)\n",
    "    paths = [[os.path.join(dn, fn) for fn in files] for dn, _ , files in os.walk(images_dir)]\n",
    "    paths = sum(paths, [])\n",
    "    crop_images(paths)\n",
    "    for path in paths:\n",
    "        new_path = split_image_digits(path)\n",
    "        new_image_paths.append(new_path)\n",
    "    return new_image_paths\n",
    "    \n",
    "# def preprocess_image_data(image_path, n):\n",
    "#     new_images = [os.path.join(image_path, fn) for fn in os.listdir(image_path)]\n",
    "#     img1 = cv2.imread(new_images[0], cv2.IMREAD_GRAYSCALE)\n",
    "#     img2 = cv2.imread(new_images[1], cv2.IMREAD_GRAYSCALE)\n",
    "#     img3 = cv2.imread(new_images[2], cv2.IMREAD_GRAYSCALE)\n",
    "#     #imgs = [img1.flatten(), img2.flatten(), img3.flatten()]\n",
    "#     imgs = [img1, img2, img3]\n",
    "#     dfs = {}\n",
    "#     for i in range(len(imgs)):\n",
    "#         img = imgs[i]\n",
    "#         name = \"image{}\".format((i+1)+n)\n",
    "#         df = img_to_dict(img)\n",
    "#         dfs[name] = df\n",
    "#     return dfs\n",
    "\n",
    "# def img_to_dict(img):\n",
    "#     p = 0\n",
    "#     res = {}\n",
    "#     for i in range(img.shape[0]):\n",
    "#         p += 1\n",
    "#         col = \"pixel{}\".format(p)\n",
    "#         pix = img[i]\n",
    "#         res[col] = pix\n",
    "#     return res\n",
    "\n",
    "# def images_to_df(img_path, n):\n",
    "#     dfs = preprocess_image_data(img_path, n)\n",
    "#     main_df = pd.DataFrame(dfs.values(), index=dfs.keys())\n",
    "#     return main_df\n",
    "\n",
    "# def save_image_data(imgs_path):\n",
    "#     dfs = []\n",
    "#     n = 0\n",
    "#     for img_name in os.listdir(imgs_path):\n",
    "#         img_path = os.path.join(imgs_path, img_name)\n",
    "#         df = images_to_df(img_path, n)\n",
    "#         dfs.append(df)\n",
    "#         n += 3\n",
    "#     main_df = pd.DataFrame()\n",
    "#     for df in dfs:\n",
    "#         if len(main_df) == 0:\n",
    "#             main_df = df\n",
    "#         else:\n",
    "#             main_df = pd.concat([main_df, df])\n",
    "#     df_save_dir = os.path.join(os.getcwd(), \"output\")\n",
    "#     if not os.path.exists(df_save_dir):\n",
    "#         os.mkdir(df_save_dir)\n",
    "#     main_df.to_csv(os.path.join(df_save_dir, \"image_pixels_{}.csv\".format(int(time.time()))))\n",
    "#     return main_df\n",
    "    \n",
    "def train_predict_digits(X, y, digit=1):\n",
    "    X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "    y_train_digit = (y_train == digit)\n",
    "    y_test_digit = (y_test == digit)\n",
    "    sgd_clf = SGDClassifier(random_state=42)\n",
    "    sgd_clf.fit(X_train, y_train_digit)\n",
    "    sgd_clf.predict(X_test[0])\n",
    "    scores = cross_val_score(sgd_clf, X_train, y_train_digit, cv=3, scoring=\"accuracy\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\py_repos\\image_classifier\\datasets\\newer_images\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_image_digits(path):\n",
    "    img = cv2.imread(path)\n",
    "    img1 = img[0:44, 0:92]\n",
    "    img2 = img[0:44, 92:184]\n",
    "    img3 = img[0:44, 184:276]\n",
    "    # img1 = img1.reshape(-1, 4048).astype(np.int8)\n",
    "    # img2 = img2.reshape(-1, 4048).astype(np.int8)\n",
    "    # img3 = img3.reshape(-1, 4048).astype(np.int8)\n",
    "    return img1, img2, img3\n",
    "\n",
    "def normalize_img(img):\n",
    "    img = img * 1.0/255\n",
    "    return img\n",
    "\n",
    "def crop_images(paths):\n",
    "    i = 0\n",
    "    img_dir = os.path.join(os.getcwd(), \"datasets\", \"images\")\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "    for path in paths:\n",
    "        i += 1\n",
    "        new_img_path = os.path.join(img_dir, \"img{}.png\".format(i))\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img_data[0:45, 0:278]\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "\n",
    "def create_image_data(img_dirname, outdirname=\"newer_images\"):\n",
    "    images_dir = os.path.join(os.getcwd(), \"datasets\", img_dirname)\n",
    "    outdir = os.path.join(os.getcwd(), \"datasets\", outdirname)\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    paths = [[os.path.join(dn, fn) for fn in files] for dn, _ , files in os.walk(images_dir)]\n",
    "    paths = sum(paths, [])\n",
    "    crop_images(paths)\n",
    "    i = 0\n",
    "    for path in paths:\n",
    "        img1, img2, img3 = split_image_digits(path)\n",
    "        path1 = os.path.join(outdir, \"image{}.png\".format(i+1))\n",
    "        path2 = os.path.join(outdir, \"image{}.png\".format(i+2))\n",
    "        path3 = os.path.join(outdir, \"image{}.png\".format(i+3))\n",
    "        cv2.imwrite(path1, img1)\n",
    "        cv2.imwrite(path2, img2)\n",
    "        cv2.imwrite(path3, img3)\n",
    "        i += 3\n",
    "    return outdir\n",
    "\n",
    "img1_path = os.path.join(os.getcwd(), \"datasets\", \"images\", \"img1.png\")\n",
    "\n",
    "new_path = create_image_data(\"images\")\n",
    "print(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = os.path.join(os.getcwd(), \"datasets\", \"newer_images\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    " \n",
    "img_path = os.path.join(os.getcwd(), \"datasets\", \"digits\", \"digits.png\")\n",
    "img = cv.imread(img_path)\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    " \n",
    "# Now we split the image to 5000 cells, each 20x20 size\n",
    "cells = [np.hsplit(row,100) for row in np.vsplit(gray,50)]\n",
    " \n",
    "# Make it into a Numpy array: its size will be (50,100,20,20)\n",
    "x = np.array(cells)\n",
    " \n",
    "# Now we prepare the training data and test data\n",
    "train = x[:,:50].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    "test = x[:,50:100].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    " \n",
    "# Create labels for train and test data\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k,250)[:,np.newaxis]\n",
    "test_labels = train_labels.copy()\n",
    " \n",
    "# Initiate kNN, train it on the training data, then test it with the test data with k=1\n",
    "knn = cv.ml.KNearest_create()\n",
    "knn.train(train, cv.ml.ROW_SAMPLE, train_labels)\n",
    "ret,result,neighbours,dist = knn.findNearest(test,k=5)\n",
    " \n",
    "# Now we check the accuracy of classification\n",
    "# For that, compare the result with test_labels and check which are wrong\n",
    "matches = result==test_labels\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = correct*100.0/result.size\n",
    "print( accuracy )\n",
    "\n",
    "# Save the data\n",
    "np.savez('knn_data.npz',train=train, train_labels=train_labels)\n",
    " \n",
    "# Now load the data\n",
    "with np.load('knn_data.npz') as data:\n",
    "    print( data.files )\n",
    "    train = data['train']\n",
    "    train_labels = data['train_labels']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
