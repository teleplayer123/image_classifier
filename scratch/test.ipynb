{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycoral.adapters import classify, common\n",
    "# from pycoral.utils.edgetpu import make_interpreter\n",
    "# import platform\n",
    "# import tflite_runtime.interpreter as tflite\n",
    "\n",
    "# _EDGETPU_SHARED_LIB = {\n",
    "#   'Linux': 'libedgetpu.so.1',\n",
    "#   'Darwin': 'libedgetpu.1.dylib',\n",
    "#   'Windows': 'edgetpu.dll'\n",
    "# }[platform.system()]\n",
    "\n",
    "# print(_EDGETPU_SHARED_LIB)\n",
    "\n",
    "# interp = tflite.load_delegate(_EDGETPU_SHARED_LIB)\n",
    "\n",
    "# print(help(interp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import fetch_openml\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "\n",
    "# def get_mnist784_dataset():\n",
    "#     data_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "#     if not os.path.exists(data_dir):\n",
    "#         os.mkdir(data_dir)\n",
    "#     mnist_dir =  os.path.join(os.getcwd(), \"datasets\", \"mnist_784\")\n",
    "#     if not os.path.exists(mnist_dir):\n",
    "#         os.mkdir(mnist_dir)\n",
    "\n",
    "#     mnist = fetch_openml('mnist_784', as_frame=False)\n",
    "#     data_df = pd.DataFrame(mnist.data, columns=mnist.feature_names)\n",
    "#     target_df = pd.DataFrame(mnist.target, columns=mnist.target_names)\n",
    "#     data_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_data.csv\")\n",
    "#     target_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_target.csv\")\n",
    "#     data_df.to_csv(data_path)\n",
    "#     target_df.to_csv(target_path)\n",
    "#     X, y = mnist.data, mnist.target\n",
    "#     return X, y\n",
    "\n",
    "# def mnist784_df_from_csv():\n",
    "#     data_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_data.csv\")\n",
    "#     target_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_target.csv\")\n",
    "#     data_df = pd.read_csv(data_path)\n",
    "#     target_df = pd.read_csv(target_path)\n",
    "#     X_df, y_df = data_df, target_df\n",
    "#     X_df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "#     y_df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "#     return X_df, y_df\n",
    "\n",
    "# def train_predict_mnist784():\n",
    "#     X_df, y_df = mnist784_df_from_csv()\n",
    "#     X = X_df.values\n",
    "#     y = y_df.values\n",
    "#     some_digit = X[0]\n",
    "#     X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "#     y_train_5 = (y_train == 5)\n",
    "#     y_test_5 = (y_test == 5)\n",
    "#     sgd_clf = SGDClassifier(random_state=42)\n",
    "#     sgd_clf.fit(X_train, y_train_5)\n",
    "#     sgd_clf.predict([some_digit])\n",
    "#     scores = cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "#     return scores\n",
    "\n",
    "# res = train_predict_mnist784()\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_1 (Reshape)         (1, 44, 92, 1)            0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (1, 42, 90, 32)           320       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (1, 40, 88, 32)           9248      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (1, 112640)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (1, 10)                   1126410   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (1, 130)                  1430      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1137408 (4.34 MB)\n",
      "Trainable params: 1137408 (4.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "input_shape = (44, 92)\n",
    "n_outputs = 130\n",
    "\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\", input_shape=(44, 92, 1)),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# model.add(data_augmentation)\n",
    "# model.add(tf.keras.Input(shape=input_shape))\n",
    "model.add(tf.keras.layers.Reshape(target_shape=(input_shape[0], input_shape[1], 1)))\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model.add(tf.keras.layers.Dense(n_outputs))\n",
    "\n",
    "x = tf.ones((1, 44, 92, 1))\n",
    "y = model(x)\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 8.9794 - accuracy: 0.0250 - val_loss: 14.4672 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 8.8417 - accuracy: 0.0250 - val_loss: 14.2381 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 8.7642 - accuracy: 0.0250 - val_loss: 14.0454 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 8.9348 - accuracy: 0.0250 - val_loss: 13.9360 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 9.1983 - accuracy: 0.0250 - val_loss: 13.8720 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9.0828 - accuracy: 0.0250 - val_loss: 13.7815 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9.0607 - accuracy: 0.0250 - val_loss: 13.7019 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9.0121 - accuracy: 0.0250 - val_loss: 13.6178 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 8.9434 - accuracy: 0.0250 - val_loss: 13.5047 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 9.3482 - accuracy: 0.0250 - val_loss: 13.4152 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9.6024 - accuracy: 0.0250 - val_loss: 13.3751 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9.7118 - accuracy: 0.0000e+00 - val_loss: 13.3411 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9.6325 - accuracy: 0.0250 - val_loss: 13.2687 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 9.6249 - accuracy: 0.0500 - val_loss: 13.2001 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 9.7919 - accuracy: 0.0250 - val_loss: 13.0924 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 9.9660 - accuracy: 0.0250 - val_loss: 12.9668 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10.1493 - accuracy: 0.0250 - val_loss: 12.8434 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 10.2918 - accuracy: 0.0250 - val_loss: 12.6854 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 10.2005 - accuracy: 0.0250 - val_loss: 12.5132 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 10.7210 - accuracy: 0.0250 - val_loss: 12.3672 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 10.9143 - accuracy: 0.0250 - val_loss: 12.3469 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 10.8059 - accuracy: 0.0250 - val_loss: 12.3153 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 10.7548 - accuracy: 0.0250 - val_loss: 12.1822 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10.8817 - accuracy: 0.0250 - val_loss: 12.0272 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 10.9639 - accuracy: 0.0250 - val_loss: 11.8411 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 11.0255 - accuracy: 0.0250 - val_loss: 11.6643 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 10.8514 - accuracy: 0.0250 - val_loss: 11.3652 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 10.5525 - accuracy: 0.0250 - val_loss: 10.7757 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 10.1962 - accuracy: 0.0250 - val_loss: 9.5507 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 8.7271 - accuracy: 0.0250 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 4.8675 - accuracy: 0.0000e+00 - val_loss: 4.8675 - val_accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.8675 - accuracy: 0.0000e+00\n",
      "Loss Average: 7.359286101659139\n",
      "Accuracy Average: 0.012500000186264515\n",
      "Loss: 4.867534637451172\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def normalize_img(img):\n",
    "    img = img * 1.0/255\n",
    "    return img\n",
    "\n",
    "def imgs_to_dict(image_dir):\n",
    "    img_dict = {}\n",
    "    for fname in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, fname)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        name = fname.split(\".\")[0]\n",
    "        idx = name.split(\"image\")[-1]\n",
    "        img_dict[idx] = img\n",
    "    return img_dict\n",
    "\n",
    "def images_to_arr(obj):\n",
    "    imgs = []\n",
    "    if isinstance(obj, dict):\n",
    "        imgs = [normalize_img(img) for img in obj.values()]\n",
    "    elif isinstance(obj, str):\n",
    "        dir_path = None \n",
    "        if os.path.isdir(imgs):\n",
    "            dir_path = imgs\n",
    "        else:\n",
    "            dir_path = os.path.join(os.getcwd(), obj)\n",
    "        for fname in sorted(os.listdir(dir_path)):\n",
    "            img_path = os.path.join(dir_path, fname)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = normalize_img(img)\n",
    "            imgs.append(img)\n",
    "    else:\n",
    "        raise TypeError(f\"type {type(obj)} is not supported\")\n",
    "    return np.array(imgs)\n",
    "\n",
    "dirpath = r\"C:\\py_repos\\image_classifier\\integer_images\"\n",
    "\n",
    "d = imgs_to_dict(dirpath)\n",
    "a = images_to_arr(d)\n",
    "targets = np.array([int(i) for i in list(d.keys())])\n",
    "\n",
    "x_train, x_test = a[:40], a[40:50]\n",
    "y_train, y_test = np.array(targets[:40]), np.array(targets[40:50]) \n",
    "x_val, y_val = np.array(a[50:51]), np.array(targets[50:51])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=60)\n",
    "model.evaluate(x_val, y_val)\n",
    "scores = history.history\n",
    "loss = np.average(scores[\"loss\"])\n",
    "accuracy = np.average(scores[\"accuracy\"])\n",
    "print(\"Loss Average: {}\".format(loss))\n",
    "print(\"Accuracy Average: {}\".format(accuracy))\n",
    "print(\"Loss: {}\".format(scores[\"loss\"][-1]))\n",
    "print(\"Accuracy: {}\".format(scores[\"accuracy\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "initial_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(44, 92, 3)),\n",
    "        tf.keras.layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=[layer.output for layer in initial_model.layers],\n",
    ")\n",
    "\n",
    "# Call feature extractor on test input.\n",
    "x = tf.ones((1, 44, 92, 1))\n",
    "features = feature_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(784)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10),\n",
    "])\n",
    "\n",
    "# Presumably you would want to first load pre-trained weights.\n",
    "model.load_weights(...)\n",
    "\n",
    "# Freeze all layers except the last one.\n",
    "for layer in model.layers[:-1]:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Recompile and train (this will only update the weights of the last layer).\n",
    "model.compile(...)\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(250, 250, 3)))  # 250x250 RGB images\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "# Can you guess what the current output shape is at this point? Probably not.\n",
    "# Let's just print it:\n",
    "model.summary()\n",
    "\n",
    "# The answer was: (40, 40, 32), so we can keep downsampling...\n",
    "\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "# And now?\n",
    "model.summary()\n",
    "\n",
    "# Now that we have 4x4 feature maps, time to apply global max pooling.\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "model.add(layers.Dense(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
