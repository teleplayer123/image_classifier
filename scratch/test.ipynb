{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycoral.adapters import classify, common\n",
    "# from pycoral.utils.edgetpu import make_interpreter\n",
    "# import platform\n",
    "# import tflite_runtime.interpreter as tflite\n",
    "\n",
    "# _EDGETPU_SHARED_LIB = {\n",
    "#   'Linux': 'libedgetpu.so.1',\n",
    "#   'Darwin': 'libedgetpu.1.dylib',\n",
    "#   'Windows': 'edgetpu.dll'\n",
    "# }[platform.system()]\n",
    "\n",
    "# print(_EDGETPU_SHARED_LIB)\n",
    "\n",
    "# interp = tflite.load_delegate(_EDGETPU_SHARED_LIB)\n",
    "\n",
    "# print(help(interp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import fetch_openml\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "\n",
    "# def get_mnist784_dataset():\n",
    "#     data_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "#     if not os.path.exists(data_dir):\n",
    "#         os.mkdir(data_dir)\n",
    "#     mnist_dir =  os.path.join(os.getcwd(), \"datasets\", \"mnist_784\")\n",
    "#     if not os.path.exists(mnist_dir):\n",
    "#         os.mkdir(mnist_dir)\n",
    "\n",
    "#     mnist = fetch_openml('mnist_784', as_frame=False)\n",
    "#     data_df = pd.DataFrame(mnist.data, columns=mnist.feature_names)\n",
    "#     target_df = pd.DataFrame(mnist.target, columns=mnist.target_names)\n",
    "#     data_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_data.csv\")\n",
    "#     target_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_target.csv\")\n",
    "#     data_df.to_csv(data_path)\n",
    "#     target_df.to_csv(target_path)\n",
    "#     X, y = mnist.data, mnist.target\n",
    "#     return X, y\n",
    "\n",
    "# def mnist784_df_from_csv():\n",
    "#     data_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_data.csv\")\n",
    "#     target_path = os.path.join(os.getcwd(), \"datasets\", \"mnist_784\", \"mnist_784_target.csv\")\n",
    "#     data_df = pd.read_csv(data_path)\n",
    "#     target_df = pd.read_csv(target_path)\n",
    "#     X_df, y_df = data_df, target_df\n",
    "#     X_df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "#     y_df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "#     return X_df, y_df\n",
    "\n",
    "# def train_predict_mnist784():\n",
    "#     X_df, y_df = mnist784_df_from_csv()\n",
    "#     X = X_df.values\n",
    "#     y = y_df.values\n",
    "#     some_digit = X[0]\n",
    "#     X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "#     y_train_5 = (y_train == 5)\n",
    "#     y_test_5 = (y_test == 5)\n",
    "#     sgd_clf = SGDClassifier(random_state=42)\n",
    "#     sgd_clf.fit(X_train, y_train_5)\n",
    "#     sgd_clf.predict([some_digit])\n",
    "#     scores = cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "#     return scores\n",
    "\n",
    "# res = train_predict_mnist784()\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_144 (Sequential  (None, 44, 92, 1)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " reshape_19 (Reshape)        (None, 44, 92, 1)         0         \n",
      "                                                                 \n",
      " conv2d_201 (Conv2D)         (None, 42, 90, 32)        320       \n",
      "                                                                 \n",
      " conv2d_202 (Conv2D)         (None, 40, 88, 32)        9248      \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 112640)            0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 64)                7209024   \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 130)               8450      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7227042 (27.57 MB)\n",
      "Trainable params: 7227042 (27.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "input_shape = (44, 92)\n",
    "n_outputs = 130\n",
    "\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\", input_shape=(44, 92, 1)),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(data_augmentation)\n",
    "# model.add(tf.keras.Input(shape=input_shape))\n",
    "model.add(tf.keras.layers.Reshape(target_shape=(input_shape[0], input_shape[1], 1)))\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model.add(tf.keras.layers.Dense(n_outputs))\n",
    "\n",
    "x = tf.ones((1, 44, 92, 1))\n",
    "y = model(x)\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 10.4089 - accuracy: 0.0000e+00 - val_loss: 14.1645 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 9.2325 - accuracy: 0.0333 - val_loss: 13.3057 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 8.8000 - accuracy: 0.0333 - val_loss: 14.0584 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 8.3263 - accuracy: 0.0333 - val_loss: 14.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 8.1188 - accuracy: 0.0333 - val_loss: 15.8134 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 7.9307 - accuracy: 0.0333 - val_loss: 15.6016 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 7.7557 - accuracy: 0.0333 - val_loss: 15.3846 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 7.6788 - accuracy: 0.0333 - val_loss: 15.2667 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 7.5565 - accuracy: 0.0667 - val_loss: 15.1434 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 7.4423 - accuracy: 0.0667 - val_loss: 15.0313 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 7.3648 - accuracy: 0.0333 - val_loss: 14.9376 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 7.2635 - accuracy: 0.0333 - val_loss: 14.7565 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 6.8339 - accuracy: 0.0333 - val_loss: 14.6324 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 6.7603 - accuracy: 0.0667 - val_loss: 14.4283 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 6.6068 - accuracy: 0.0667 - val_loss: 14.2621 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 6.6201 - accuracy: 0.0333 - val_loss: 14.1495 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.5362 - accuracy: 0.0667 - val_loss: 13.9034 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.4298 - accuracy: 0.0667 - val_loss: 13.5820 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 6.2919 - accuracy: 0.0667 - val_loss: 13.5460 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.5166 - accuracy: 0.0667 - val_loss: 13.3740 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 6.1899 - accuracy: 0.1667 - val_loss: 13.4771 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 7.3377 - accuracy: 0.0667 - val_loss: 13.6756 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 7.2174 - accuracy: 0.0333 - val_loss: 13.3609 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 7.2578 - accuracy: 0.0667 - val_loss: 13.1872 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 7.2783 - accuracy: 0.0333 - val_loss: 13.0529 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.5489 - accuracy: 0.0667 - val_loss: 13.0250 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.9789 - accuracy: 0.2000 - val_loss: 13.1038 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 6.6902 - accuracy: 0.2000 - val_loss: 13.0512 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.3306 - accuracy: 0.2000 - val_loss: 12.9036 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 6.4121 - accuracy: 0.1000 - val_loss: 12.7328 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 6.7859 - accuracy: 0.1000 - val_loss: 12.5581 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 6.9520 - accuracy: 0.0333 - val_loss: 12.4880 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 7.6777 - accuracy: 0.0333 - val_loss: 12.5698 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 7.3691 - accuracy: 0.1000 - val_loss: 12.6168 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 7.6791 - accuracy: 0.1000 - val_loss: 12.8397 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 7.2069 - accuracy: 0.1333 - val_loss: 13.1698 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 7.1571 - accuracy: 0.1333 - val_loss: 13.4037 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 8.0802 - accuracy: 0.0667 - val_loss: 13.2731 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 7.2294 - accuracy: 0.1333 - val_loss: 12.3592 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 6.9190 - accuracy: 0.1667 - val_loss: 11.2865 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.8726 - accuracy: 0.0667 - val_loss: 10.9855 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 5.5275 - accuracy: 0.1000 - val_loss: 5.2913 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 5.4785 - accuracy: 0.0333 - val_loss: 9.7581 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.4496 - accuracy: 0.1667 - val_loss: 9.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 6.3537 - accuracy: 0.0667 - val_loss: 5.6094 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 5.6189 - accuracy: 0.1667 - val_loss: 9.0601 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 4.8778 - accuracy: 0.1333 - val_loss: 9.9695 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.3840 - accuracy: 0.1667 - val_loss: 10.0255 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 5.0327 - accuracy: 0.1333 - val_loss: 9.6658 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.9147 - accuracy: 0.0333 - val_loss: 8.7241 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.7054 - accuracy: 0.0667 - val_loss: 8.2040 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 9.1609 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 5.0585 - accuracy: 0.0333 - val_loss: 7.8469 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 4.8675 - accuracy: 0.0667 - val_loss: 7.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 7.1901 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.7056 - accuracy: 0.0333 - val_loss: 6.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 4.7055 - accuracy: 0.0333 - val_loss: 6.8692 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 4.7060 - accuracy: 0.0333 - val_loss: 6.8912 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 6.9041 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 6.9136 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 6.9159 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 6.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 6.9113 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 4.7062 - accuracy: 0.0333 - val_loss: 7.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 4.9655 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.8675 - accuracy: 0.0333 - val_loss: 4.8675 - val_accuracy: 0.0000e+00\n",
      "Loss Average: 5.881391763687134\n",
      "Accuracy Average: 0.058333335779607295\n",
      "Loss: 4.867534160614014\n",
      "Accuracy: 0.03333333507180214\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def normalize_img(img):\n",
    "    img = img * 1.0/255\n",
    "    return img\n",
    "\n",
    "def imgs_to_dict(image_dir):\n",
    "    img_dict = {}\n",
    "    for fname in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, fname)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        name = fname.split(\".\")[0]\n",
    "        idx = name.split(\"image\")[-1]\n",
    "        img_dict[idx] = img\n",
    "    return img_dict\n",
    "\n",
    "def images_to_arr(obj):\n",
    "    imgs = []\n",
    "    if isinstance(obj, dict):\n",
    "        imgs = [normalize_img(img) for img in obj.values()]\n",
    "    elif isinstance(obj, str):\n",
    "        dir_path = None \n",
    "        if os.path.isdir(imgs):\n",
    "            dir_path = imgs\n",
    "        else:\n",
    "            dir_path = os.path.join(os.getcwd(), obj)\n",
    "        for fname in sorted(os.listdir(dir_path)):\n",
    "            img_path = os.path.join(dir_path, fname)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = normalize_img(img)\n",
    "            imgs.append(img)\n",
    "    else:\n",
    "        raise TypeError(f\"type {type(obj)} is not supported\")\n",
    "    return np.array(imgs)\n",
    "\n",
    "dirpath = r\"C:\\py_repos\\image_classifier\\integer_images\"\n",
    "\n",
    "d = imgs_to_dict(dirpath)\n",
    "a = images_to_arr(d)\n",
    "targets = np.array([int(i) for i in list(d.keys())])\n",
    "\n",
    "x_train, x_test = a[:30], a[30:40]\n",
    "y_train, y_test = np.array(targets[:30]), np.array(targets[30:40]) \n",
    "x_val, y_val = np.array(a[40:50]), np.array(targets[40:50])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100)\n",
    "# model.evaluate(x_val, y_val)\n",
    "scores = history.history\n",
    "loss = np.average(scores[\"loss\"])\n",
    "accuracy = np.average(scores[\"accuracy\"])\n",
    "print(\"Loss Average: {}\".format(loss))\n",
    "print(\"Accuracy Average: {}\".format(accuracy))\n",
    "print(\"Loss: {}\".format(scores[\"loss\"][-1]))\n",
    "print(\"Accuracy: {}\".format(scores[\"accuracy\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "initial_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(44, 92, 3)),\n",
    "        tf.keras.layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=[layer.output for layer in initial_model.layers],\n",
    ")\n",
    "\n",
    "# Call feature extractor on test input.\n",
    "x = tf.ones((1, 44, 92, 1))\n",
    "features = feature_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(784)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10),\n",
    "])\n",
    "\n",
    "# Presumably you would want to first load pre-trained weights.\n",
    "model.load_weights(...)\n",
    "\n",
    "# Freeze all layers except the last one.\n",
    "for layer in model.layers[:-1]:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Recompile and train (this will only update the weights of the last layer).\n",
    "model.compile(...)\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(250, 250, 3)))  # 250x250 RGB images\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "# Can you guess what the current output shape is at this point? Probably not.\n",
    "# Let's just print it:\n",
    "model.summary()\n",
    "\n",
    "# The answer was: (40, 40, 32), so we can keep downsampling...\n",
    "\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "# And now?\n",
    "model.summary()\n",
    "\n",
    "# Now that we have 4x4 feature maps, time to apply global max pooling.\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "model.add(layers.Dense(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
